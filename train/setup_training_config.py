import os

# Training mode: 'full' or 'lora'
mode = 'full'

# Training hyperparameters
adjust_train_epochs = 3
adjust_learning_rate = 8e-6  # Default: 4e-5
model_size = '1'  # Options: '1', '2', '8'

# Script file configuration
adjust_file = f'internvl3_{model_size}b_dynamic_res_2nd_finetune_{mode}.sh'
save_file = f'internvl3_{model_size}b_dynamic_res_2nd_finetune_{mode}_building.sh'
sh_dir = 'InternVL/internvl_chat/shell/internvl3.0/2nd_finetune'

# Output directory for the fine-tuned model
adjust_OUTPUT_DIR = f'InternVL/models/InternVL3-{model_size}B-finetuned'

# Base model path (downloaded pre-trained InternVL model, see https://internvl.readthedocs.io/en/latest/internvl3.0/finetune.html)
adjust_model_path = f"InternVL/models/InternVL3-{model_size}B"

# Path to training data configuration (generated by prepare_train_data.py)
adjust_meta_path = f'InternVL/internvl_chat/shell/data/internvl_finetune_building.json'

# Whether to freeze the backbone during training
adjust_freeze_backbone = False

def apply_config_replacements(filedata, replacements):
    """Apply multiple string replacements to the file data."""
    for old_str, new_str in replacements:
        if old_str not in filedata:
            raise ValueError(f"String not found in file: '{old_str}'")
        filedata = filedata.replace(old_str, new_str)
    return filedata

with open(os.path.join(sh_dir, adjust_file), 'r') as file:
    filedata = file.read()

# Define all replacements
# Handle multiple possible learning rate strings in the source script
_lr_candidates = ['--learning_rate 1e-5', '--learning_rate 2e-5']
_lr_replacements = [(c, f'--learning_rate {adjust_learning_rate}') for c in _lr_candidates]
_lr_replacements = [pair for pair in _lr_replacements if pair[0] in filedata]

replacements = [
    (f"work_dirs/internvl_chat_v3/internvl3_{model_size}b_dynamic_res_2nd_finetune_full", f"{adjust_OUTPUT_DIR}"),
    ('--meta_path "./shell/data/internvl_1_2_finetune_custom.json"', f'--meta_path "{adjust_meta_path}"'),
    ('--num_train_epochs 1', f'--num_train_epochs {adjust_train_epochs}'),
    ('--freeze_backbone True', f'--freeze_backbone {adjust_freeze_backbone}'),
    (f'--model_name_or_path "OpenGVLab/InternVL3-{model_size}B"', f'--model_name_or_path "{adjust_model_path}"'),
] + _lr_replacements

# Apply all replacements
filedata = apply_config_replacements(filedata, replacements)

print(f"- Adjusting training configuration...")
print(f"- Source script: {os.path.join(sh_dir, adjust_file)}")
print(f"- Output script: {os.path.join(sh_dir, save_file)}")
print(f"- Training epochs: {adjust_train_epochs}")
print(f"- Learning rate: {adjust_learning_rate}")
print(f"- Output directory: {adjust_OUTPUT_DIR}")
print(f"- Base model: {adjust_model_path}")
print(f"- Freeze backbone: {adjust_freeze_backbone}")

with open(os.path.join(sh_dir, save_file), 'w') as file:
    file.write(filedata)

print("Training configuration script created successfully!")
print(f"=== Run the following command to start training: === ")
print(f"cd <your-model-path>/InternVL/internvl_chat")
print(f"GPUS=1 PER_DEVICE_BATCH_SIZE=1 sh shell/internvl3.0/2nd_finetune/{save_file}")